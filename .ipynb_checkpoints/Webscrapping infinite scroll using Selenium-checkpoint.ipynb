{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only use Selenium for extracting href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    " \n",
    "# def scrape_url(base_url):\n",
    " \n",
    "#     # Load WebDriver and navigate to the page url.\n",
    "#     # This will open a browser window.\n",
    "#     driver = webdriver.Chrome(\"C:/Users/Gabriela/Programming/courses/Python_mega_course_app4_to_10/app7_Real_Estate_Webscraper/chromedriver.exe\")\n",
    "#     driver.get(base_url)\n",
    "     \n",
    "#     #initiate list to store property-specififc URLs in    \n",
    "#     urls = []\n",
    " \n",
    "#     #  get number of results --> used to determine over how many pages to iterate\n",
    "#     property_nr = int(driver.find_element_by_class_name('results-label').get_attribute('data-count'))\n",
    "#     driver.quit()\n",
    "#     print(f\"Number of properties: {property_nr}\")\n",
    "    \n",
    "#     # calculate number of pages to scroll over and round up float \n",
    "#     total_pages = math.ceil(property_nr/100) #Note use math.ceil() instead of np.ceil() to return int instead of float\n",
    "    \n",
    "#     #iterate over total_pages and add info to base_URL\n",
    "#     for i in range(1,total_pages+1):\n",
    "#         url = base_url + f\"&p={i}\"\n",
    "#         driver = webdriver.Chrome(\"C:/Users/Gabriela/Programming/courses/Python_mega_course_app4_to_10/app7_Real_Estate_Webscraper/chromedriver.exe\")\n",
    "#         driver.get(url)\n",
    "        \n",
    "#         #initiate scroll_count in order to avoid infinite loop on final page\n",
    "#         scroll_count =0\n",
    "        \n",
    "#         # First scroll to the end of the table by sending Page Down keypresses to\n",
    "#         # the browser window.\n",
    "#         print(f'Scrolling through page {i} of {total_pages}')\n",
    "#         while driver.find_elements_by_tag_name('h3')[-1].text != \"You've Seen the next 100 properties.\" \\\n",
    "#         and driver.find_elements_by_tag_name('h3')[-1].text != \"You've Seen the first 100 properties.\" \\\n",
    "#         and scroll_count < 200:\n",
    "#             # Find the first element on the page, so we can scroll down using the\n",
    "#             # element object's send_keys() method\n",
    "#             scroll_count +=1\n",
    "#             elem = driver.find_element_by_class_name('listing-price')\n",
    "#             elem.send_keys(Keys.PAGE_DOWN)\n",
    "\n",
    "#         # Once the whole table has loaded, grab all the visible links. \n",
    "#         print(f'Saving property URLs for page {i} to list.')\n",
    "#         visible_links = driver.find_elements_by_class_name('listing-price')\n",
    "#         for link in visible_links:\n",
    "#             urls.append(link.get_attribute('href'))\n",
    "#         if i == total_pages:\n",
    "#             pass\n",
    "#         else:\n",
    "#             print(f\"{len(urls)} properties stored to list.\")\n",
    "\n",
    "#         driver.quit()\n",
    "    \n",
    "#     print(f\"Done. {len(urls)} property URLs saved to list.\")\n",
    "    \n",
    "#     return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Selenium to extract more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    " \n",
    "def scrape_url(base_url):\n",
    "     \n",
    "    #start timer\n",
    "    start = datetime.now()\n",
    "        \n",
    "    # Load WebDriver and navigate to the page url.\n",
    "    # This will open a browser window.\n",
    "    driver = webdriver.Chrome(\"C:/Users/Gabriela/Programming/courses/Python_mega_course_app4_to_10/app7_Real_Estate_Webscraper/chromedriver.exe\")\n",
    "    driver.get(base_url)\n",
    "     \n",
    "    #initiate list to store property-specififc URLs in    \n",
    "    urls = []\n",
    " \n",
    "    #  get number of results --> used to determine over how many pages to iterate\n",
    "    property_nr = int(driver.find_element_by_class_name('results-label').get_attribute('data-count'))\n",
    "    driver.quit()\n",
    "    print(f\"Number of properties: {property_nr}\")\n",
    "    \n",
    "    # calculate number of pages to scroll over and round up float \n",
    "    total_pages = math.ceil(property_nr/100) #Note use math.ceil() instead of np.ceil() to return int instead of float\n",
    "    \n",
    "    #iterate over total_pages and add info to base_URL\n",
    "    for i in range(1,total_pages+1):\n",
    "        url = base_url + f\"&p={i}\"\n",
    "        driver = webdriver.Chrome(\"C:/Users/Gabriela/Programming/courses/Python_mega_course_app4_to_10/app7_Real_Estate_Webscraper/chromedriver.exe\")\n",
    "        driver.get(url)\n",
    "        \n",
    "        #initiate scroll_count in order to avoid infinite loop on final page\n",
    "        scroll_count =0\n",
    "        \n",
    "        # First scroll to the end of the table by sending Page Down keypresses to\n",
    "        # the browser window.\n",
    "        print(f'Scrolling through page {i} of {total_pages}')\n",
    "        while driver.find_elements_by_tag_name('h3')[-1].text != \"You've Seen the next 100 properties.\" \\\n",
    "        and driver.find_elements_by_tag_name('h3')[-1].text != \"You've Seen the first 100 properties.\" \\\n",
    "        and scroll_count < 200:\n",
    "            # Find the first element on the page, so we can scroll down using the\n",
    "            # element object's send_keys() method\n",
    "            scroll_count +=1\n",
    "            elem = driver.find_element_by_class_name('listing-price')\n",
    "            elem.send_keys(Keys.PAGE_DOWN)\n",
    "\n",
    "        # Once the whole table has loaded, grab all the visible links. \n",
    "        print(f'Saving property URLs for page {i} to list.')\n",
    "        visible_links = driver.find_elements_by_class_name('property-card-primary-info')\n",
    "        \n",
    "        for link in visible_links:\n",
    "            info = {}\n",
    "            #get mandatory information\n",
    "            href = link.find_element_by_class_name(\"listing-price\").get_attribute('href')\n",
    "            \n",
    "            price = link.find_element_by_class_name(\"listing-price\").text.strip()\n",
    "            try:\n",
    "                price = int(''.join(c for c in price if c.isdigit())) #string non-numeric symbold and convert price to int\n",
    "            except:\n",
    "                price = price\n",
    "                \n",
    "            try:\n",
    "                street = link.find_element_by_class_name(\"property-address\").get_attribute('title')\n",
    "            except:\n",
    "                street = np.nan\n",
    "            try:\n",
    "                location = link.find_element_by_class_name(\"property-city\").text.strip()\n",
    "                neighborhood = location.split()[0]\n",
    "                zip_ = location.split()[-1]\n",
    "            except:\n",
    "                location = np.nan\n",
    "                neighborhood = np.nan\n",
    "                zip_ = np.nan\n",
    "              \n",
    "            #get optional information\n",
    "            try:\n",
    "                beds = int(link.find_element_by_class_name(\"property-beds\").find_element_by_tag_name(\"strong\").text)\n",
    "            except:\n",
    "                beds = np.nan\n",
    "            try:\n",
    "                baths = int(link.find_element_by_class_name(\"property-baths\").find_element_by_tag_name(\"strong\").text)\n",
    "            except:\n",
    "                baths = np.nan\n",
    "            try:\n",
    "                size = int(link.find_element_by_class_name(\"property-sqft\").find_element_by_tag_name(\"strong\").text)\n",
    "            except:\n",
    "                size = np.nan\n",
    "\n",
    "                \n",
    "            #add information to info-dict\n",
    "            info['href'] = href\n",
    "            info['Price'] = price\n",
    "            info['Bedrooms'] = beds\n",
    "            info['Bathrooms'] = baths\n",
    "            info['Size'] = size\n",
    "            info['Street'] = street\n",
    "            info['zip'] = zip_\n",
    "            info['address'] = street + ', ' + location\n",
    "            \n",
    "            #append to urls-list\n",
    "            urls.append(info)\n",
    "        if i == total_pages:\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"{len(urls)} properties stored to list.\")\n",
    "\n",
    "        driver.quit()\n",
    "    \n",
    "    print(f\"Done. {len(urls)} property URLs saved to list.\")\n",
    "    \n",
    "    #end timer\n",
    "    end = datetime.now()\n",
    "    #calculate elapsed time\n",
    "    print(f\"\\nScraping took {end-start}.\")\n",
    "    \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of properties: 807\n",
      "Scrolling through page 1 of 9\n",
      "Saving property URLs for page 1 to list.\n",
      "100 properties stored to list.\n",
      "Scrolling through page 2 of 9\n",
      "Saving property URLs for page 2 to list.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-228-bca3ba08ea61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0murls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscrape_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://www.century21.com/real-estate/brooklyn-ny/LCNYBROOKLYN/?sa=CNYASTORIA%2CCNYBREEZYPOINT%2CCNYELMHURST%2CCNYHOWARDBEACH%2CCNYJACKSONHEIGHTS%2CCNYLONGISLANDCITY%2CCNYMASPETH%2CCNYMIDDLEVILLAGE%2CCNYOZONEPARK%2CCNYREGOPARK%2CCNYRIDGEWOOD%2CCNYSUNNYSIDE%2CCNYWOODHAVEN%2CCNYWOODSIDE&pr=%7C350000\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-227-9b1a596fc102>\u001b[0m in \u001b[0;36mscrape_url\u001b[1;34m(base_url)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Street'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstreet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'zip'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'address'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstreet\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;31m#append to urls-list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "urls = scrape_url(\"https://www.century21.com/real-estate/brooklyn-ny/LCNYBROOKLYN/?sa=CNYASTORIA%2CCNYBREEZYPOINT%2CCNYELMHURST%2CCNYHOWARDBEACH%2CCNYJACKSONHEIGHTS%2CCNYLONGISLANDCITY%2CCNYMASPETH%2CCNYMIDDLEVILLAGE%2CCNYOZONEPARK%2CCNYREGOPARK%2CCNYRIDGEWOOD%2CCNYSUNNYSIDE%2CCNYWOODHAVEN%2CCNYWOODSIDE&pr=%7C350000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'href': 'https://www.century21.com/property/7401-4th-avenue-e7-brooklyn-ny-11209-CBR51643402',\n",
       "  'Price': '$320,000',\n",
       "  'Bedrooms': 1,\n",
       "  'Bathrooms': 1,\n",
       "  'size': nan},\n",
       " {'href': 'https://www.century21.com/property/1170-ocean-parkway-8-g-brooklyn-ny-11230-REN014069992',\n",
       "  'Price': '$205,000',\n",
       "  'Bedrooms': 1,\n",
       "  'Bathrooms': 1,\n",
       "  'size': nan},\n",
       " {'href': 'https://www.century21.com/property/86-29-shore-parkway-unit-0008-howard-beach-ny-11414-C2182174151',\n",
       "  'Price': '$315,000',\n",
       "  'Bedrooms': 2,\n",
       "  'Bathrooms': 1,\n",
       "  'size': nan}]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(urls))\n",
    "urls[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use requests and BeautifulSoup to get more specific information from property-hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"pdp-info-address\" itemprop=\"streetAddress\">88-05 Shore Parkway Unit 006 <span itemprop=\"addressLocality\">Howard Beach</span>, <span itemprop=\"addressRegion\">NY</span> <span itemprop=\"postalCode\">11414</span></div> \n",
      "\n",
      "{'Address': '88-05 Shore Parkway Unit 006 Howard Beach, NY 11414', 'Street': '88-05 Shore Parkway Unit 006 ', 'Location': 'Howard Beach', 'Zip': '11414', 'Price': 239000, 'Bedrooms': '1', 'Bathrooms': '1'}\n"
     ]
    }
   ],
   "source": [
    "def get_realEstate_info(info_dict):\n",
    "    d = {}\n",
    "    d['link'] = info_dict['href']\n",
    "    # get property-website content\n",
    "    r = requests.get(url, headers={'User-agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:61.0) Gecko/20100101 Firefox/61.0'})\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    \n",
    "    #check if listing is for sale\n",
    "    if soup.find(\"div\", {\"class\":\"pdp-listing-type\"}).text.lower() == 'for sale' \\\n",
    "        or soup.find(\"div\", {\"class\":\"pdp-listing-type\"}).text.lower() == 'sale':\n",
    "\n",
    "        # extract information\n",
    "        # address\n",
    "\n",
    "        d['Address'] = info_dict['Address']\n",
    "        d['Street'] = info_dict['Street']\n",
    "        d['Zip'] = info_dict['zip']\n",
    "        # price\n",
    "        price = soup.find(\"div\", {\"class\":\"pdp-info-price\"}).find(\"h5\").text.strip()\n",
    "        # delete non-numeric values and convert to int\n",
    "        price = int(''.join(c for c in price if c.isdigit()))\n",
    "        d['Price'] = price\n",
    "        \n",
    "        # bath and bedrooms\n",
    "        b_b = soup.find(\"div\", {\"class\":\"pdp-info-bbsa\"}).find_all(\"span\", {\"class\":\"pdp-info-bbsa-element\"})\n",
    "#         iterate over list (including beds and baths)\n",
    "        for b in b_b:\n",
    "#         if 'beds' can be found in b.text, save text of <b>-child-tag to dict\n",
    "            if 'beds' in b.text:\n",
    "                d['Bedrooms'] = b.b.text\n",
    "            if 'baths' in b.text:\n",
    "                d['Bathrooms'] = b.b.text\n",
    "    print(d)\n",
    "    \n",
    "get_realEstate_info('https://www.century21.com/property/88-05-shore-parkway-unit-006-howard-beach-ny-11414-C2182157685')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebElement' object has no attribute 'ext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-211-d30721316522>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/Gabriela/Programming/courses/Python_mega_course_app4_to_10/app7_Real_Estate_Webscraper/chromedriver.exe\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.century21.com/property/7401-4th-avenue-e7-brooklyn-ny-11209-CBR51643402'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pdp-info-price'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_tag_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'WebElement' object has no attribute 'ext'"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"C:/Users/Gabriela/Programming/courses/Python_mega_course_app4_to_10/app7_Real_Estate_Webscraper/chromedriver.exe\")\n",
    "driver.get('https://www.century21.com/property/7401-4th-avenue-e7-brooklyn-ny-11209-CBR51643402')\n",
    "print(driver.find_element_by_class_name('pdp-info-price').find_element_by_tag_name('h5').ext)\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
